<!DOCTYPE html>
<html>
<head>
    <title>The Spines Overlay Messaging System: Documentation</title>
    <link rel="stylesheet" type="text/css" href="../dsn_style.css">
</head>

<body>
    <div class="full-wrapper">

<div class="dsn-nav">
    <ul>
        <li><a href="https://jhu-dsn.github.io">Home</a></li>
        <li><a href="https://jhu-dsn.github.io/about-us.html">About Us</a></li>
        <li><a href="https://jhu-dsn.github.io/research.html">Research</a></li>
        <li><a href="https://jhu-dsn.github.io/people.html">People</a></li>
        <li><a href="https://jhu-dsn.github.io/photos.html">Photos</a></li>
        <li><a href="https://jhu-dsn.github.io/funding.html">Funding</a></li>
        <li><a href="https://jhu-dsn.github.io/publications.html">Publications</a></li>
        <li><a href="https://jhu-dsn.github.io/software.html">Software</a></li>
    </ul>
</div>


    <div class="main-wrapper">

        <div class="large-title">
        <h1>Spines</h1>
        </div>

<div class="page-nav">
<ul>
    <li> <a href="/">Home</a> </li>
    <li> <a href="/documentation">Documentation</a> </li>
    <li> <a href="/LICENSE.txt">License</a> </li>
    <li> <a href="http://jhu-dsn.github.io/download/download_spines.cgi">Download</a> </li>
    <li> <a href="http://lists.cnds.jhu.edu/mailman/listinfo/spines-users/">Mailing List</a> </li>
    <li> <a href="/credits.html">Credits</a> </li>
</ul>
</div>
        <div class="top-border-box">
        <div class="large-title">
        <h2> Documentation </h2>
        </div>
        </div> <!-- top-border-box --!>

        <div class="textbox">

Spines is a messaging infrastructure that allows multi-hop communication
(unicast, multicast, and anycast), and deployment of virtual topologies on real
networks. Spines instantiates a virtual router node on every participating
computer and creates virtual links between these nodes. Packets are routed
automatically in through the network topology. Many Spines topologies can
coexist in the same physical network, and even overlap on some of the nodes or
links.

<p>
Client applications connect to one of the router nodes (usually the closest)
and send and receive messages from that node. Spines is responsible to forward
application messages towards the nodes that have destination applications. If
multiple applications intend to communicate using Spines, they must connect to
nodes of the same Spines network.

<p>
Spines runs a software daemon on each of the router nodes. The daemon acts both
as a router, forwarding packets toward other nodes, and as a server, providing
network services to client applications. Clients use a library to connect to a
Spines daemon and send and receive messages. The API is almost identical to the
Unix Socket interface. Virtually any socket-based application can be easily
adapted to work with Spines. Spines API provides TCP and UDP-like functions
with similar semantics for both reliable, and best effort communication.

<p>
A client can communicate with a daemon via TCP, UDP, or IPC (Inter-Process
Communication). IPC uses unix socket domains (not available on Windows-based
architectures), and was added to Spines in version 5.1.

<p>
For IPC communication, the Spines daemon binds to two file paths, one for the
control channel and one for the data channel. The control channel binds to the
default or user-specified path (e.g., /tmp/spines8100), and the data channel
binds to the control channel path with a "data" suffix (e.g.,
/tmp/spines8100data). Clients just need to specify the (normal) control
channel path; the data channel path is handled automatically. Normally, the
Spines daemon unlinks and cleans up the paths it creates. However, in case of
a hard daemon crash that is not handled, the files must be cleaned up
manually.

<p>
A <I>spines_socket()</I> call returns a socket, which is actually a connection
to the daemon. The application can use that socket to bind, listen, connect,
send and receive, using Spines library calls (e.g. <I>spines_send()</I> is the
equivalent to the regular <I>send()</I> call, <I>spines_recv()</I> is
equivalent to <I>recv()</I>, etc.).

<p>
When connecting to a daemon using <I>spines_socket()</I>, the client specifies
several options (as part of the protocol parameter) to specify the type of
connection. For example, the client can specify the type of link protocol used
to send its messages between daemons in the Spines network, the type of
dissemination semantics to use, and the type of session semantics to apply to
its messages (currently, this last option only applies to intrusion-tolerant
reliable communication). Full details of these options can be found in the
<I>spines_socket()</I> specification.

<p>
Each application can be uniquely identified in the topology by the pair of
(Logical ID, Virtual Port). Currently, the logical ID of an application is the
IPv4 IP address of the daemon it is connected to, and the virtual port is an
identifier at the daemon. The virtual port of an application is either assigned
automatically by the server node upon application connect, or it is set
explicitly by the application in a call similar to the Unix bind(). Both
reliable and best effort communication between two applications connected to
the Spines network are done using the IP address and the virtual port described
above in a way similar to TCP and UDP. Note that the virtual port of an
application is only defined in relationship with a Spines node, and is not
related to an operating system port of the computer the application or the
daemon is running on.

<p>
A multicast group is defined as a class D multicast address and an anycast
group as a class E address. If an application intends to join a group, it
informs its server (router node) about this with a spines_setsockopt() call.
From there on, the server will pass to the application the messages sent to
that group. Leaving a group follows a similar procedure. In order to
multicast/anycast a message to a group, an application simply sends the message
(through its server) to the multicast/anycast address representing the group.
The Spines network handles the routing of the multicast message according to
the current membership of the group the message is sent to. Applications can
join, leave, send and receive messages to and from multicast groups at any
time. An application can join multiple groups, thus it can be member of more
than one group at the same time. An application does not need to be a member of
a group in order to send messages to that group.

<p>
Spines can also manage kernel routing tables by updating native kernel routes
with those determined by the overlay topology and the chosen metric. In this
case, Spines is acting as an overlay routing daemon where regular user packets
(without any knowledge of Spines) are routed seamlessly in kernel-level between
overlay nodes. As data packets are not processed by Spines, they are not copied
to user-space, and therefore the routing overhead is substantially reduced.
This reduction in CPU consumption can greatly benefit low cost routers, such as
the Linksys WRT54G. Note that, in this mode, certain Spines protocols cannot be
activated as packets are routed by the underlying kernel services. In addition,
kernel-routing services are available in Spines to support anypath and
multipath routing based on group membership.

<p>
Documentation about the new intrusion tolerance capabilities added in version
5.0 (and refined in versions 5.1 and 5.2) can be found <a href="/doc_intrusion_tolerance/">here</a>.

<p>
The current version of Spines was tested to run on Linux X86 computers.
<p>
<h4>The Spines Daemon</h4>
<pre>
<a href="/documentation/spines_daemon.html">spines</a> [-p spines_port] [-l logical_id] [-I local_address] [[-a destination]*]
       [[-d discovery_address]*] [-w Route_Type] [-tf] [-sf] [-m] [-x time_to_live]
       [-U] [-W] [-k level] [-lf log_file] [-ud unix_domain_path] [-pc]
       [-rl <rate (kbps)>] [-c config_file]
</pre>

<p>
<h4>Setting topology parameters</h4>
<pre>
<a href="/documentation/setlink.html">setlink</a> bandwidth(kbps) latency(ms) loss_rate(%) burst_rate(%) source_ip destination_ip [port]
</pre>
<p>
<h4>The Spines API</h4>
<a href="/documentation/spines_init.html">spines_init()</a><br>
<a href="/documentation/spines_socket.html">spines_socket()</a><br>
<a href="/documentation/spines_close.html">spines_close()</a><br>
<a href="/documentation/spines_bind.html">spines_bind()</a><br>
<a href="/documentation/spines_sendto.html">spines_sendto()</a><br>
<a href="/documentation/spines_recvfrom.html">spines_recvfrom()</a><br>
<a href="/documentation/spines_connect.html">spines_connect()</a><br>
<a href="/documentation/spines_send.html">spines_send()</a><br>
<a href="/documentation/spines_recv.html">spines_recv()</a><br>
<a href="/documentation/spines_listen.html">spines_listen()</a><br>
<a href="/documentation/spines_accept.html">spines_accept()</a><br>
<a href="/documentation/spines_setsockopt.html">spines_setsockopt()</a><br>
<a href="/documentation/spines_ioctl.html">spines_ioctl()</a><br>

    </div> <!-- textbox -->

    </div> <!-- main-wrapper -->

<div class="dsn-foot-wrapper">
    <div class="dsn-foot">
    Distributed Systems and Networks Lab <br>
    Computer Science Department, Johns Hopkins University <br>
    Malone Hall <br>
    3400 North Charles Street <br>
    Baltimore, MD 21218 <br>
    </div>
</div>

    </div> <!-- full-wrapper -->
</body>

</html>
